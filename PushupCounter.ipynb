{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b6dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 376 images belonging to 3 classes.\n",
      "Found 84 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import distutils\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\hp\\Downloads\\data\\PUSHUP\\data\\train',\n",
    "    target_size=(64, 64),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\hp\\Downloads\\data\\PUSHUP\\data\\validation',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bb9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.Input(shape=(64,64,3)))\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(6, (3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  model.add(tf.keras.layers.Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "  #model.add(tf.keras.layers.BatchNormalization())\n",
    "  model.add(tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))  \n",
    "\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(512))\n",
    "  model.add(tf.keras.layers.Activation('relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(128))\n",
    "  model.add(tf.keras.layers.Activation('relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(64))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(3))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012cd554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 [==============================] - 9s 349ms/step - loss: 0.9966 - categorical_accuracy: 0.4574 - val_loss: 0.7416 - val_categorical_accuracy: 0.7976\n",
      "Epoch 2/15\n",
      "24/24 [==============================] - 8s 348ms/step - loss: 0.6501 - categorical_accuracy: 0.7686 - val_loss: 0.2930 - val_categorical_accuracy: 0.8690\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 9s 379ms/step - loss: 0.4568 - categorical_accuracy: 0.8484 - val_loss: 0.2653 - val_categorical_accuracy: 0.8810\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 11s 479ms/step - loss: 0.4503 - categorical_accuracy: 0.8590 - val_loss: 0.5312 - val_categorical_accuracy: 0.7857\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 11s 479ms/step - loss: 0.3903 - categorical_accuracy: 0.8431 - val_loss: 0.3244 - val_categorical_accuracy: 0.9048\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 12s 502ms/step - loss: 0.3424 - categorical_accuracy: 0.8883 - val_loss: 0.2323 - val_categorical_accuracy: 0.9286\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 14s 586ms/step - loss: 0.3134 - categorical_accuracy: 0.8963 - val_loss: 0.3121 - val_categorical_accuracy: 0.9048\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 13s 535ms/step - loss: 0.3809 - categorical_accuracy: 0.8564 - val_loss: 0.2213 - val_categorical_accuracy: 0.9286\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 12s 495ms/step - loss: 0.3436 - categorical_accuracy: 0.8883 - val_loss: 0.2210 - val_categorical_accuracy: 0.9286\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 12s 483ms/step - loss: 0.3531 - categorical_accuracy: 0.8856 - val_loss: 0.1917 - val_categorical_accuracy: 0.9405\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 12s 516ms/step - loss: 0.3485 - categorical_accuracy: 0.9016 - val_loss: 0.1833 - val_categorical_accuracy: 0.9524\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 14s 611ms/step - loss: 0.3030 - categorical_accuracy: 0.9255 - val_loss: 0.2860 - val_categorical_accuracy: 0.9405\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 14s 597ms/step - loss: 0.2307 - categorical_accuracy: 0.9229 - val_loss: 0.2157 - val_categorical_accuracy: 0.9405\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 24s 1s/step - loss: 0.2912 - categorical_accuracy: 0.9016 - val_loss: 0.2248 - val_categorical_accuracy: 0.9405\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 20s 834ms/step - loss: 0.2737 - categorical_accuracy: 0.9016 - val_loss: 0.2102 - val_categorical_accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_freq=1\n",
    ")\n",
    "\n",
    "model.save('model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4574004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fff529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f84119",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test_video.mov\")\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "out = cv2.VideoWriter('output_count1.avi',fourcc, 20.0,(int(cap.get(3)),int(cap.get(4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426cfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "i= 0\n",
    "prediction_str = \"\"\n",
    "repetitions = 0\n",
    "up = 0\n",
    "down = 0\n",
    "no_move = 0\n",
    "current_move = 0\n",
    "initial = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe5e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):\n",
    "    i+=1\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    if not(ret): break\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    \n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    image = cv2.resize(rgb, (64, 64))\n",
    "    image = image.reshape((1,) + image.shape)\n",
    "    image = image/255.0\n",
    "    prediction = np.argmax(model.predict(image), axis=-1)[0]\n",
    "    \n",
    "    if prediction == 0:\n",
    "        down +=1 \n",
    "        if down == 3:\n",
    "          if initial == -1:\n",
    "            initial = 0\n",
    "          if current_move == 2:\n",
    "            repetitions+=1\n",
    "          current_move = 0\n",
    "        elif down > 0:\n",
    "          up = 0\n",
    "          no_move = 0\n",
    "    elif prediction == 2:\n",
    "        up += 1\n",
    "        if up == 3 and initial != -1:\n",
    "          current_move = 2\n",
    "        elif up > 1:\n",
    "          down = 0 \n",
    "          no_move = 0\n",
    "    else:\n",
    "        no_move += 1\n",
    "        if no_move == 15:\n",
    "          current_move = 1\n",
    "        elif no_move > 10:\n",
    "          up = 0\n",
    "          down = 0 \n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,600)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 5\n",
    "    #print(repetitions)\n",
    "    cv2.putText(frame2, \"Repetitions: \"+ str(repetitions),bottomLeftCornerOfText,font, fontScale,fontColor,lineType)\n",
    "    out.write(frame2)\n",
    "    prvs = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1f01c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Generated\n"
     ]
    }
   ],
   "source": [
    "print(\"Video Generated\")\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76480add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
